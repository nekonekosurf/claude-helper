"""ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ - æ„å‘³ãƒ™ãƒ¼ã‚¹ã®æ–‡æ›¸æ¤œç´¢ï¼ˆfastembed + numpyï¼‰"""

import json
import numpy as np
from pathlib import Path

INDEX_DIR = Path(__file__).parent.parent / "data" / "index"

_model = None
_embeddings = None
_chunks = None


def _load_model():
    """åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›ã®ã¿ï¼‰"""
    global _model
    if _model is not None:
        return

    from fastembed import TextEmbedding
    # è»½é‡ãªå¤šè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆCPUå¯¾å¿œï¼‰
    _model = TextEmbedding("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")


def _load_embeddings():
    """äº‹å‰è¨ˆç®—ã—ãŸåŸ‹ã‚è¾¼ã¿ã‚’ãƒ­ãƒ¼ãƒ‰"""
    global _embeddings, _chunks

    if _embeddings is not None:
        return

    emb_path = INDEX_DIR / "embeddings.npy"
    chunks_path = INDEX_DIR / "chunks.json"

    if not emb_path.exists():
        raise FileNotFoundError(
            f"ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæœªæ§‹ç¯‰ã§ã™ã€‚"
            f"'uv run python -m src.vector_search build' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        )

    _embeddings = np.load(str(emb_path))

    with open(chunks_path, encoding="utf-8") as f:
        _chunks = json.load(f)


def build_embeddings(batch_size: int = 64):
    """å…¨ãƒãƒ£ãƒ³ã‚¯ã®åŸ‹ã‚è¾¼ã¿ã‚’è¨ˆç®—ã—ã¦ä¿å­˜"""
    _load_model()

    chunks_path = INDEX_DIR / "chunks.json"
    if not chunks_path.exists():
        print("Error: chunks.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã« indexer.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    with open(chunks_path, encoding="utf-8") as f:
        chunks = json.load(f)

    texts = [c["text"] for c in chunks]
    print(f"ğŸ”¢ {len(texts)} ãƒãƒ£ãƒ³ã‚¯ã®åŸ‹ã‚è¾¼ã¿ã‚’è¨ˆç®—ä¸­...")

    # ãƒãƒƒãƒã§åŸ‹ã‚è¾¼ã¿è¨ˆç®—
    all_embeddings = list(_model.embed(texts, batch_size=batch_size))
    embedding_matrix = np.array(all_embeddings, dtype=np.float32)

    # ä¿å­˜
    emb_path = INDEX_DIR / "embeddings.npy"
    np.save(str(emb_path), embedding_matrix)

    print(f"âœ… åŸ‹ã‚è¾¼ã¿ä¿å­˜å®Œäº†: {emb_path}")
    print(f"   å½¢çŠ¶: {embedding_matrix.shape}")


def search(query: str, top_k: int = 5, doc_filter: str | None = None) -> list[dict]:
    """ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ - æ„å‘³çš„ã«è¿‘ã„ãƒãƒ£ãƒ³ã‚¯ã‚’è¿”ã™"""
    _load_model()
    _load_embeddings()

    # ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿ã‚’è¨ˆç®—
    query_emb = list(_model.embed([query]))[0]
    query_emb = np.array(query_emb, dtype=np.float32)

    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
    # æ­£è¦åŒ–
    query_norm = query_emb / (np.linalg.norm(query_emb) + 1e-10)
    emb_norms = _embeddings / (np.linalg.norm(_embeddings, axis=1, keepdims=True) + 1e-10)
    similarities = emb_norms @ query_norm

    # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
    if doc_filter:
        for i, chunk in enumerate(_chunks):
            if doc_filter not in chunk["doc_id"]:
                similarities[i] = -1

    # ä¸Šä½Nä»¶
    top_indices = np.argsort(similarities)[::-1][:top_k]

    results = []
    for idx in top_indices:
        score = float(similarities[idx])
        if score <= 0:
            break
        chunk = _chunks[idx]
        results.append({
            "doc_id": chunk["doc_id"],
            "chunk_id": chunk["chunk_id"],
            "filename": chunk["filename"],
            "text": chunk["text"],
            "score": round(score, 4),
            "method": "vector",
        })

    return results


def is_available() -> bool:
    """ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹"""
    return (INDEX_DIR / "embeddings.npy").exists()


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "build":
        build_embeddings()
    else:
        print("Usage: python -m src.vector_search build")
